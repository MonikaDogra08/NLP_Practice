{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TextBlob\n",
    "\n",
    "- TextBlob, which is another extremely powerful NLP library for Python. TextBlob is built upon NLTK and provides an easy to use interface to the NLTK library. We will see how TextBlob can be used to perform a variety of NLP tasks ranging from parts-of-speech tagging to sentiment analysis, and language translation to text classification.\n",
    "\n",
    "- This lib is an advance and good as compared to Nltk lib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization :\n",
    "\n",
    "- Tokenization refers to splitting a large paragraph into sentences or words. Typically, a token refers to a word in a text document. Tokenization is pretty straight forward with TextBlob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\monik\\anaconda3\\lib\\site-packages (0.15.3)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\monik\\anaconda3\\lib\\site-packages (from textblob) (3.5)\n",
      "Requirement already satisfied: joblib in c:\\users\\monik\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (0.17.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\monik\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (4.50.2)\n",
      "Requirement already satisfied: click in c:\\users\\monik\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (7.1.2)\n",
      "Requirement already satisfied: regex in c:\\users\\monik\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (2020.10.15)\n"
     ]
    }
   ],
   "source": [
    "# install textblob\n",
    "\n",
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\monik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\monik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\monik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\monik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package conll2000 to\n",
      "[nltk_data]     C:\\Users\\monik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\monik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# In text blob we donot need to download model again and again so do :\n",
    "\n",
    "!python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lib :\n",
    "\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word and sentence tokenization :\n",
    "document = (\"In computer science, artificial intelligence (AI), \\\n",
    "            sometimes called machine intelligence, is intelligence \\\n",
    "            demonstrated by machines, in contrast to the natural intelligence \\\n",
    "            displayed by humans and animals. Computer science defines AI \\\n",
    "            research as the study of \\\"intelligent agents\\\": any device that \\\n",
    "            perceives its environment and takes actions that maximize its\\\n",
    "            chance of successfully achieving its goals.[1] Colloquially,\\\n",
    "            the term \\\"artificial intelligence\\\" is used to describe machines\\\n",
    "            that mimic \\\"cognitive\\\" functions that humans associate with other\\\n",
    "            human minds, such as \\\"learning\\\" and \\\"problem solving\\\".[2]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['In', 'computer', 'science', 'artificial', 'intelligence', 'AI', 'sometimes', 'called', 'machine', 'intelligence', 'is', 'intelligence', 'demonstrated', 'by', 'machines', 'in', 'contrast', 'to', 'the', 'natural', 'intelligence', 'displayed', 'by', 'humans', 'and', 'animals', 'Computer', 'science', 'defines', 'AI', 'research', 'as', 'the', 'study', 'of', 'intelligent', 'agents', 'any', 'device', 'that', 'perceives', 'its', 'environment', 'and', 'takes', 'actions', 'that', 'maximize', 'its', 'chance', 'of', 'successfully', 'achieving', 'its', 'goals', '1', 'Colloquially', 'the', 'term', 'artificial', 'intelligence', 'is', 'used', 'to', 'describe', 'machines', 'that', 'mimic', 'cognitive', 'functions', 'that', 'humans', 'associate', 'with', 'other', 'human', 'minds', 'such', 'as', 'learning', 'and', 'problem', 'solving', '2'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  pass the doc as a parameter to the TextBlob class :the words attribute returns the tokenized words in the document.\n",
    "\n",
    "token = TextBlob(document)\n",
    "token.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sentence(\"In computer science, artificial intelligence (AI),             sometimes called machine intelligence, is intelligence             demonstrated by machines, in contrast to the natural intelligence             displayed by humans and animals.\"), Sentence(\"Computer science defines AI             research as the study of \"intelligent agents\": any device that             perceives its environment and takes actions that maximize its            chance of successfully achieving its goals.\"), Sentence(\"[1] Colloquially,            the term \"artificial intelligence\" is used to describe machines            that mimic \"cognitive\" functions that humans associate with other            human minds, such as \"learning\" and \"problem solving\".\"), Sentence(\"[2]\")]\n",
      "\n",
      " Total sentences are : 4\n"
     ]
    }
   ],
   "source": [
    "# sentence tokenization: we can use the sentences attribute\n",
    "\n",
    "sent = token.sentences\n",
    "print(sent)\n",
    "print()\n",
    "print(f\" Total sentences are : {len(sent)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming and Lemmatization\n",
    "\n",
    "- Lemmatization refers to reducing the word to its root form as found in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'histori'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import word :\n",
    "\n",
    "from textblob import Word\n",
    "s =Word('history')\n",
    "s.stem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = Word('went')\n",
    "l.lemmatize('v')\n",
    "\n",
    "#  By default, the words are treated as nouns by the lemmatize() method. so need to pass 'v' means specify this is a verb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The complete list for the parts of speech components is as follows: ADJ, ADJ_SAT, ADV, NOUN, VERB = 'a', 's', 'r', 'n', 'v'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parts of Speech (POS) Tagging:\n",
    "\n",
    "- Like the NLTK library, the TextBlob library also contains functionalities for the POS tagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In => IN\n",
      "computer => NN\n",
      "science => NN\n",
      "artificial => JJ\n",
      "intelligence => NN\n",
      "AI => NNP\n",
      "sometimes => RB\n",
      "called => VBD\n",
      "machine => NN\n",
      "intelligence => NN\n",
      "is => VBZ\n",
      "intelligence => NN\n",
      "demonstrated => VBN\n",
      "by => IN\n",
      "machines => NNS\n",
      "in => IN\n",
      "contrast => NN\n",
      "to => TO\n",
      "the => DT\n",
      "natural => JJ\n",
      "intelligence => NN\n",
      "displayed => VBN\n",
      "by => IN\n",
      "humans => NNS\n",
      "and => CC\n",
      "animals => NNS\n",
      "Computer => NNP\n",
      "science => NN\n",
      "defines => NNS\n",
      "AI => NNP\n",
      "research => NN\n",
      "as => IN\n",
      "the => DT\n",
      "study => NN\n",
      "of => IN\n",
      "intelligent => JJ\n",
      "agents => NNS\n",
      "any => DT\n",
      "device => NN\n",
      "that => WDT\n",
      "perceives => VBZ\n",
      "its => PRP$\n",
      "environment => NN\n",
      "and => CC\n",
      "takes => VBZ\n",
      "actions => NNS\n",
      "that => IN\n",
      "maximize => VB\n",
      "its => PRP$\n",
      "chance => NN\n",
      "of => IN\n",
      "successfully => RB\n",
      "achieving => VBG\n",
      "its => PRP$\n",
      "goals => NNS\n",
      "[ => RB\n",
      "1 => CD\n",
      "] => NNP\n",
      "Colloquially => NNP\n",
      "the => DT\n",
      "term => NN\n",
      "artificial => JJ\n",
      "intelligence => NN\n",
      "is => VBZ\n",
      "used => VBN\n",
      "to => TO\n",
      "describe => VB\n",
      "machines => NNS\n",
      "that => IN\n",
      "mimic => JJ\n",
      "cognitive => JJ\n",
      "functions => NNS\n",
      "that => WDT\n",
      "humans => NNS\n",
      "associate => VBP\n",
      "with => IN\n",
      "other => JJ\n",
      "human => JJ\n",
      "minds => NNS\n",
      "such => JJ\n",
      "as => IN\n",
      "learning => VBG\n",
      "and => CC\n",
      "problem => NN\n",
      "solving => NN\n",
      "[ => RB\n",
      "2 => CD\n",
      "] => NNS\n"
     ]
    }
   ],
   "source": [
    "for word, pos in token.tags:\n",
    "    print(word + \" => \" + pos)\n",
    "\n",
    "# print the tags for all the words in the paragraph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary : gives the definition of any word :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the linear extent in space from one end to the other; the longest dimension of something that is fixed in place',\n",
       " 'continuance in time',\n",
       " 'the property of being the extent of something from beginning to end',\n",
       " 'size of the gap between two places',\n",
       " 'a section of something that is long and narrow']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it uses .definitions to return the explainantion of any word exidting in the dictionary :\n",
    "\n",
    "Word('length').definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ellipse in which the two axes are of equal length; a plane curve generated by one point moving at a constant distance from a fixed point',\n",
       " 'an unofficial association of people or groups',\n",
       " 'something approximating the shape of a circle',\n",
       " 'movement once around a course',\n",
       " 'a road junction at which traffic streams circularly around a central island',\n",
       " 'street names for flunitrazepan',\n",
       " 'a curved section or tier of seats in a hall or theater or opera house; usually the first tier above the orchestra',\n",
       " 'any circular or rotating mechanism',\n",
       " 'travel around something',\n",
       " 'move in circles',\n",
       " 'form a circle around']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Word('Circle').definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Text to Singular and Plural :\n",
    "\n",
    "- TextBlob also allows you to convert text into a plural or singular form using the pluralize and singularize methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['Use', '4', 'space', 'per', 'indentation', 'level'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = TextBlob('Use 4 spaces per indentation level')\n",
    "\n",
    "# convert text in to singular\n",
    "text.words.singularize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'space'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert spaces in to singular\n",
    "text.words[2].singularize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['Uses', '4s', 'spacess', 'pers', 'indentations', 'levels'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert text in to plural\n",
    "text.words.pluralize()\n",
    "\n",
    "# behind the scene they maintain words from dictionary : but if word is not in the dictionary then, just adds 's' and removes 's'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noun Phrase Extraction :\n",
    "\n",
    "- Noun phrase extraction, as the name suggests, refers to extracting phrases that contain nouns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computer science\n",
      "artificial intelligence\n",
      "ai\n",
      "machine intelligence\n",
      "natural intelligence\n",
      "computer\n",
      "science defines\n",
      "ai\n",
      "intelligent agents\n",
      "colloquially\n",
      "artificial intelligence\n",
      "describe machines\n",
      "human minds\n"
     ]
    }
   ],
   "source": [
    "for noun_phrase in token.noun_phrases:\n",
    "    print(noun_phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Words and Phrase Counts :\n",
    "\n",
    "- we used Python's built-in len method to count the number of sentences, words and noun-phrases returned by the TextBlob object. We can use TextBlob's built-in methods for the same purpose.\n",
    "- To find the frequency of occurrence of a particular word, we have to pass the name of the word as the index to the word_counts list of the TextBlob object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_blob_object = TextBlob(document)\n",
    "text_blob_object.word_counts['intelligence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_blob_object.noun_phrases.count('artificial intelligence')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spelling Corrections:\n",
    "- Spelling correction is one of the unique functionalities of the TextBlob library. With the correct method of the TextBlob object, you can correct all the spelling mistakes in your text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love to watch football, but I have never played it\n"
     ]
    }
   ],
   "source": [
    "text = \"I love to watchf footbal, but I have neter played it\"\n",
    "text_blob_object = TextBlob(text)\n",
    "\n",
    "print(text_blob_object.correct())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language Translation :\n",
    "\n",
    "- One of the most powerful capabilities of the TextBlob library is to translate from one language to another. On the backend, the TextBlob language translator uses the Google Translate API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"कुछ नहीं से कुछ बेहतर है\")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_blob_object_hindi = TextBlob('Somthing is better than nothing')\n",
    "\n",
    "# convert this to hindi:\n",
    "text_blob_object_hindi.translate(to = 'hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi, how are you?\n"
     ]
    }
   ],
   "source": [
    "# converting french to eng:\n",
    "text_blob_object_french = TextBlob(u'Salut comment allez-vous?')\n",
    "print(text_blob_object_french.translate(to='en'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello how are you?\n"
     ]
    }
   ],
   "source": [
    "# from Arabic to English:\n",
    "text_blob_object_arabic = TextBlob(u'مرحبا كيف حالك؟')\n",
    "print(text_blob_object_arabic.translate(to='en'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Finally, using the detect_language method, you can also detect the language of the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "es\n"
     ]
    }
   ],
   "source": [
    "text_blob_object = TextBlob(u'Hola como estas?')\n",
    "print(text_blob_object.detect_language())\n",
    "\n",
    "# es, which stands for the Spanish language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zh-CN'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob('有总比没有好')\n",
    "blob.detect_language()\n",
    "\n",
    "# zh-CN, which stands for the chinese language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Classification:\n",
    "\n",
    "TextBlob also provides basic text classification capabilities. Though,TextBlob for text classification owing to its limited capabilities, however, if you have a really limited data and you want to quickly develop a very basic text classification model, then you may use TextBlob. For advanced models,we can use machine learning libraries such as Scikit-Learn or Tensorflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''The dataset contains some dummy reviews about movies. \n",
    "You can see our training and test datasets consist of lists of tuples \n",
    "where the first element of the tuple is the text or a sentence \n",
    "while the second member of the tuple is the corresponding review or sentiment of the text.'''\n",
    "\n",
    "train_data = [\n",
    "    ('This is an excellent movie', 'pos'),\n",
    "    ('The move was fantastic I like it', 'pos'),\n",
    "    ('You should watch it, it is brilliant', 'pos'),\n",
    "    ('Exceptionally good', 'pos'),\n",
    "    (\"Wonderfully directed and executed. I like it\", 'pos'),\n",
    "    ('It was very boring', 'neg'),\n",
    "    ('I did not like the movie', 'neg'),\n",
    "    (\"The movie was horrible\", 'neg'),\n",
    "    ('I will not recommend', 'neg'),\n",
    "    ('The acting is pathetic', 'neg')\n",
    "]\n",
    "\n",
    "test_data = [\n",
    "    ('Its a fantastic series', 'pos'),\n",
    "    ('Never watched such a brillent movie', 'pos'),\n",
    "    (\"horrible acting\", 'neg'),\n",
    "    (\"It is a Wonderful movie\", 'pos'),\n",
    "    ('waste of money', 'neg'),\n",
    "    (\"pathetic picture\", 'neg')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use the NaiveBayesClassifier class from the textblob.classifiers library.:\n",
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "\n",
    "# To train the model, we simply have to pass the training data to the constructor of the NaiveBayesClassifier class. \n",
    "classifier = NaiveBayesClassifier(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction on a single sentence.\n",
    "\n",
    "print(classifier.classify(\"It is very boring\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify('This is an amazing library')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9065478890561054"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it can give the probability :\n",
    "\n",
    "prob = classifier.prob_classify('This is an amazing library')\n",
    "\n",
    "# probability of nagetivity in this sentence\n",
    "prob.prob('neg')\n",
    "\n",
    "# probability of positivity in this sentence\n",
    "prob.prob('pos')\n",
    "\n",
    "# this sentence is approx. 90% positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.accuracy(test_data)\n",
    "\n",
    "# In the output, you will see 0.66 which is the accuracy of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
