{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming \n",
    "\n",
    "Stemming is an important part of the pipelining process in Natural language processing. The input to the stemmer is tokenized words.\n",
    "- Stemming brings words in the stem (basic) form\n",
    "- Problem with stemming is that,it produce the intermediate repersentation of the word which may or may not have any meaning\n",
    "- we use stemming where meaning of the meaning of word is not our concern\n",
    "\n",
    "\n",
    "### Stemming algorithms \n",
    "- Porter’s Stemmer algorithm : It produces the best output as compared to other stemmers and it has less error rate.\n",
    "But its applications are only limited to English words.\n",
    "- Snowball Stemmer : It in an improved version of Porter’s Stemmer.The Snowball Stemmer can map non-English words too and is having greater computational speed. \n",
    "- Lancaster Stemmer : The Lancaster stemmers are more aggressive and dynamic compared to the other two stemmers. The stemmer is really faster, but the algorithm is really confusing when dealing with small words. But they are not as efficient as Snowball Stemmers.\n",
    "\n",
    "\n",
    "#### Application : \n",
    "- Search engines \n",
    "- Domain vocabularies \n",
    "- Email spam classification etc.\n",
    "\n",
    "\n",
    "## Lemmatization \n",
    "\n",
    "Lemmatization is similar to stemming but it brings context to the words. So it links words with similar meaning to one word. Lemmatization is preferred over Stemming because lemmatization does morphological/structural analysis of the words.\n",
    "\n",
    "\n",
    "#### Application : \n",
    "- Chatbots \n",
    "- Question Answer application etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Stemming code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****Porter Stemmer****\n",
      "hobbi\n",
      "hobbi\n",
      "comput\n",
      "comput\n",
      "histori\n",
      "histori\n",
      "****Lancaster Stemmer****\n",
      "hobby\n",
      "hobby\n",
      "comput\n",
      "comput\n",
      "hist\n",
      "hist\n",
      "****Snowball Stemmer****\n",
      "hobbi\n",
      "hobbi\n",
      "comput\n",
      "comput\n",
      "histori\n",
      "histori\n"
     ]
    }
   ],
   "source": [
    "# Use case to show how all stemmers convert the words : define a all the stemmer\n",
    "\n",
    "from nltk.stem import PorterStemmer,LancasterStemmer,SnowballStemmer\n",
    "\n",
    "porter = PorterStemmer()\n",
    "lancaster = LancasterStemmer()\n",
    "snowball = SnowballStemmer('english')\n",
    "\n",
    "print('****Porter Stemmer****')\n",
    "\n",
    "print(porter.stem('hobby'))\n",
    "print(porter.stem('hobbies'))\n",
    "print(porter.stem('computer'))\n",
    "print(porter.stem('computations'))\n",
    "print(porter.stem('history'))\n",
    "print(porter.stem('histories'))\n",
    "\n",
    "print('****Lancaster Stemmer****')\n",
    "\n",
    "print(lancaster.stem('hobby'))\n",
    "print(lancaster.stem('hobbies'))\n",
    "print(lancaster.stem('computer'))\n",
    "print(lancaster.stem('computations'))\n",
    "print(lancaster.stem('history'))\n",
    "print(lancaster.stem('histories'))\n",
    "\n",
    "print('****Snowball Stemmer****')\n",
    "\n",
    "print(snowball.stem('hobby'))\n",
    "print(snowball.stem('hobbies'))\n",
    "print(snowball.stem('computer'))\n",
    "print(snowball.stem('computations'))\n",
    "print(snowball.stem('history'))\n",
    "print(snowball.stem('histories'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem solving :\n",
    "paragraph = \"\"\"I have three visions for India. In 3000 years of our history, people from all over \n",
    "               the world have come and invaded us, captured our lands, conquered our minds. \n",
    "               From Alexander onwards, the Greeks, the Turks, the Moguls, the Portuguese, the British,\n",
    "               the French, the Dutch, all of them came and looted us, took over what was ours. \n",
    "               Yet we have not done this to any other nation. We have not conquered anyone. \n",
    "               We have not grabbed their land, their culture, \n",
    "               their history and tried to enforce our way of life on them.\"\"\" \n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<nltk.stem.snowball.SnowballStemmer object at 0x00000251BF6DF2E0> Looks like :\n",
      "i hav three vis for ind . in 3000 year of our hist , peopl from al ov the world hav com and invad us , capt our land , conqu our mind . from alexand onward , the greek , the turk , the mog , the portugues , the brit , the french , the dutch , al of them cam and loot us , took ov what was our . yet we hav not don thi to any oth nat . we hav not conqu anyon . we hav not grab their land , their cult , their hist and tri to enforc our way of lif on them .\n",
      "\n",
      "<nltk.stem.snowball.SnowballStemmer object at 0x00000251BF6DF2E0> Looks like :\n",
      "i have three vision for india . in 3000 year of our histori , peopl from all over the world have come and invad us , captur our land , conquer our mind . from alexand onward , the greek , the turk , the mogul , the portugues , the british , the french , the dutch , all of them came and loot us , took over what wa our . yet we have not done thi to ani other nation . we have not conquer anyon . we have not grab their land , their cultur , their histori and tri to enforc our way of life on them .\n",
      "\n",
      "<nltk.stem.snowball.SnowballStemmer object at 0x00000251BF6DF2E0> Looks like :\n",
      "i have three vision for india . in 3000 year of our histori , peopl from all over the world have come and invad us , captur our land , conquer our mind . from alexand onward , the greek , the turk , the mogul , the portugues , the british , the french , the dutch , all of them came and loot us , took over what was our . yet we have not done this to ani other nation . we have not conquer anyon . we have not grab their land , their cultur , their histori and tri to enforc our way of life on them .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# convert paragraph to words in lower case :\n",
    "words = nltk.word_tokenize(paragraph.lower())\n",
    "\n",
    "# check output for all stemmers :\n",
    "\n",
    "for stemmer in (lancaster,porter,snowball):\n",
    "    print(f\"{stem} Looks like :\")\n",
    "    output = [stemmer.stem(w) for w in words]\n",
    "    print(\" \".join(output))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<nltk.stem.snowball.SnowballStemmer object at 0x00000251BF6DF2E0> Looks like :\n",
      "us mind 3000 loot anyon land year french brit lif don mog tri grab invad capt ind cult peopl three alexand turk greek cam conqu took com portugues way onward nat vis world land dutch hist yet enforc\n",
      "\n",
      "<nltk.stem.snowball.SnowballStemmer object at 0x00000251BF6DF2E0> Looks like :\n",
      "us mind 3000 loot anyon land year french british life done mogul tri grab invad captur india cultur peopl three alexand turk greek came conquer took come portugues way onward nation vision world land dutch histori yet enforc\n",
      "\n",
      "<nltk.stem.snowball.SnowballStemmer object at 0x00000251BF6DF2E0> Looks like :\n",
      "us mind 3000 loot anyon land year french british life done mogul tri grab invad captur india cultur peopl three alexand turk greek came conquer took come portugues way onward nation vision world land dutch histori yet enforc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now further : to make our data more clean we can use stopwords and remove punctuations.\n",
    "\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_word = stopwords.words(\"english\")\n",
    "punch = string.punctuation\n",
    "\n",
    "\n",
    "clean_list = []\n",
    "\n",
    "for word in set(words):\n",
    "    if(word not in stop_word and word not in punch):\n",
    "        clean_list.append(word)\n",
    "\n",
    "for stemmer in (lancaster,porter,snowball):\n",
    "    print(f\"{stem} Looks like :\")\n",
    "    output = [stemmer.stem(w) for w in clean_list]\n",
    "    print(\" \".join(output))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
