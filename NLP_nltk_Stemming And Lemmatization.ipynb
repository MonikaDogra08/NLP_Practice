{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming \n",
    "\n",
    "Stemming is an important part of the pipelining process in Natural language processing. The input to the stemmer is tokenized words.\n",
    "- Stemming brings words in the stem (basic) form\n",
    "- Problem with stemming is that,it produce the intermediate repersentation of the word which may or may not have any meaning\n",
    "- we use stemming where meaning of the word is not our concern\n",
    "\n",
    "\n",
    "### Stemming algorithms \n",
    "- Porter’s Stemmer algorithm : It produces the best output as compared to other stemmers and it has less error rate.\n",
    "But its applications are only limited to English words.\n",
    "- Snowball Stemmer : It in an improved version of Porter’s Stemmer.The Snowball Stemmer can map non-English words too and is having greater computational speed. \n",
    "- Lancaster Stemmer : The Lancaster stemmers are more aggressive and dynamic compared to the other two stemmers. The stemmer is really faster, but the algorithm is really confusing when dealing with small words. But they are not as efficient as Snowball Stemmers.\n",
    "\n",
    "\n",
    "#### Application : \n",
    "- Search engines \n",
    "- Domain vocabularies \n",
    "- Email spam classification etc.\n",
    "\n",
    "\n",
    "## Lemmatization \n",
    "\n",
    "Lemmatization convert the word into their root form.Lemmatization is similar to stemming but it brings context to the words. So it links words with similar meaning to one word. Lemmatization is preferred over Stemming because lemmatization does morphological/structural analysis of the words.\n",
    "\n",
    "\n",
    "#### Application : \n",
    "- Chatbots \n",
    "- Question Answer application etc.\n",
    "\n",
    "\n",
    "#### when to use stemming and when to lemmatization :\n",
    "- It complete depends upon the use case to use case.\n",
    "- if the real meaning of thw word is not important,use stemming otherwise lemmatization.\n",
    "- stemming is faster than lemmatization\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Stemming code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****Porter Stemmer****\n",
      "hobbi\n",
      "hobbi\n",
      "comput\n",
      "comput\n",
      "histori\n",
      "histori\n",
      "****Lancaster Stemmer****\n",
      "hobby\n",
      "hobby\n",
      "comput\n",
      "comput\n",
      "hist\n",
      "hist\n",
      "****Snowball Stemmer****\n",
      "hobbi\n",
      "hobbi\n",
      "comput\n",
      "comput\n",
      "histori\n",
      "histori\n"
     ]
    }
   ],
   "source": [
    "# Use case to show how all stemmers convert the words : define all the stemmer\n",
    "\n",
    "from nltk.stem import PorterStemmer,LancasterStemmer,SnowballStemmer\n",
    "\n",
    "porter = PorterStemmer()\n",
    "lancaster = LancasterStemmer()\n",
    "snowball = SnowballStemmer('english')\n",
    "\n",
    "print('****Porter Stemmer****')\n",
    "\n",
    "print(porter.stem('hobby'))\n",
    "print(porter.stem('hobbies'))\n",
    "print(porter.stem('computer'))\n",
    "print(porter.stem('computations'))\n",
    "print(porter.stem('history'))\n",
    "print(porter.stem('histories'))\n",
    "\n",
    "print('****Lancaster Stemmer****')\n",
    "\n",
    "print(lancaster.stem('hobby'))\n",
    "print(lancaster.stem('hobbies'))\n",
    "print(lancaster.stem('computer'))\n",
    "print(lancaster.stem('computations'))\n",
    "print(lancaster.stem('history'))\n",
    "print(lancaster.stem('histories'))\n",
    "\n",
    "print('****Snowball Stemmer****')\n",
    "\n",
    "print(snowball.stem('hobby'))\n",
    "print(snowball.stem('hobbies'))\n",
    "print(snowball.stem('computer'))\n",
    "print(snowball.stem('computations'))\n",
    "print(snowball.stem('history'))\n",
    "print(snowball.stem('histories'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem solving :\n",
    "paragraph = \"\"\"I have three visions for India. In 3000 years of our history, people from all over \n",
    "               the world have come and invaded us, captured our lands, conquered our minds. \n",
    "               From Alexander onwards, the Greeks, the Turks, the Moguls, the Portuguese, the British,\n",
    "               the French, the Dutch, all of them came and looted us, took over what was ours. \n",
    "               Yet we have not done this to any other nation. We have not conquered anyone. \n",
    "               We have not grabbed their land, their culture, \n",
    "               their history and tried to enforce our way of life on them.\"\"\" \n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<LancasterStemmer> Looks like :\n",
      "i hav three vis for ind . in 3000 year of our hist , peopl from al ov the world hav com and invad us , capt our land , conqu our mind . from alexand onward , the greek , the turk , the mog , the portugues , the brit , the french , the dutch , al of them cam and loot us , took ov what was our . yet we hav not don thi to any oth nat . we hav not conqu anyon . we hav not grab their land , their cult , their hist and tri to enforc our way of lif on them .\n",
      "\n",
      "<PorterStemmer> Looks like :\n",
      "i have three vision for india . in 3000 year of our histori , peopl from all over the world have come and invad us , captur our land , conquer our mind . from alexand onward , the greek , the turk , the mogul , the portugues , the british , the french , the dutch , all of them came and loot us , took over what wa our . yet we have not done thi to ani other nation . we have not conquer anyon . we have not grab their land , their cultur , their histori and tri to enforc our way of life on them .\n",
      "\n",
      "<nltk.stem.snowball.SnowballStemmer object at 0x00000198A8127F40> Looks like :\n",
      "i have three vision for india . in 3000 year of our histori , peopl from all over the world have come and invad us , captur our land , conquer our mind . from alexand onward , the greek , the turk , the mogul , the portugues , the british , the french , the dutch , all of them came and loot us , took over what was our . yet we have not done this to ani other nation . we have not conquer anyon . we have not grab their land , their cultur , their histori and tri to enforc our way of life on them .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# convert paragraph to words in lower case :\n",
    "words = nltk.word_tokenize(paragraph.lower())\n",
    "\n",
    "# check output for all stemmers :\n",
    "\n",
    "for stemmer in (lancaster,porter,snowball):\n",
    "    print(f\"{stemmer} Looks like :\")\n",
    "    output = [stemmer.stem(w) for w in words]\n",
    "    print(\" \".join(output))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<LancasterStemmer> Looks like :\n",
      "\n",
      "three mog cult tri way nat 3000 cam capt com turk loot yet lif onward brit vis year portugues ind us don grab land land conqu invad anyon world dutch enforc mind peopl alexand french took greek hist\n",
      "\n",
      "<PorterStemmer> Looks like :\n",
      "\n",
      "three mogul cultur tri way nation 3000 came captur come turk loot yet life onward british vision year portugues india us done grab land land conquer invad anyon world dutch enforc mind peopl alexand french took greek histori\n",
      "\n",
      "<nltk.stem.snowball.SnowballStemmer object at 0x00000198A8127F40> Looks like :\n",
      "\n",
      "three mogul cultur tri way nation 3000 came captur come turk loot yet life onward british vision year portugues india us done grab land land conquer invad anyon world dutch enforc mind peopl alexand french took greek histori\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now further : to make our data more clean we can use stopwords and remove punctuations.\n",
    "\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_word = stopwords.words(\"english\")\n",
    "punch = string.punctuation\n",
    "\n",
    "\n",
    "clean_list = []\n",
    "\n",
    "for word in set(words):\n",
    "    if(word not in stop_word and word not in punch):\n",
    "        clean_list.append(word)\n",
    "\n",
    "for stemmer in (lancaster,porter,snowball):\n",
    "    print(f\"{stemmer} Looks like :\")\n",
    "    print()\n",
    "    output = [stemmer.stem(w) for w in clean_list]\n",
    "    print(\" \".join(output))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\monik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dowmload the model\n",
    "\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the library\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running\n",
      "run\n",
      "ran\n"
     ]
    }
   ],
   "source": [
    "# Use case to show how all lemmatize convert the words :\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "print(lemma.lemmatize('running'))\n",
    "print(lemma.lemmatize('runs'))\n",
    "print(lemma.lemmatize('ran'))\n",
    "\n",
    "# Here root form for running and ran should be run which didn't happen?why?\n",
    "# to solve this needs to pass pos = 'v' otherwise it may consist it as Noun or somthing else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n",
      "run\n",
      "run\n",
      "\n",
      "see\n",
      "see\n",
      "see\n"
     ]
    }
   ],
   "source": [
    "print(lemma.lemmatize('running',pos = 'v'))   \n",
    "print(lemma.lemmatize('runs',pos = 'v'))\n",
    "print(lemma.lemmatize('ran',pos = 'v'))\n",
    "print()\n",
    "print(lemma.lemmatize('see',pos = 'v'))\n",
    "print(lemma.lemmatize('sees',pos = 'v'))\n",
    "print(lemma.lemmatize('seeing',pos = 'v'))\n",
    "\n",
    "# converted the word into a root form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem solving :\n",
    "\n",
    "paragraph = \"\"\"I have three visions for India. In 3000 years of our history, people from all over \n",
    "               the world have come and invaded us, captured our lands, conquered our minds. \n",
    "               From Alexander onwards, the Greeks, the Turks, the Moguls, the Portuguese, the British,\n",
    "               the French, the Dutch, all of them came and looted us, took over what was ours. \n",
    "               Yet we have not done this to any other nation. We have not conquered anyone. \n",
    "               We have not grabbed their land, their culture, \n",
    "               their history and tried to enforce our way of life on them.\"\"\" \n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'three visions india 3000 years history people world come invade us capture land conquer mind alexander onwards greeks turks moguls portuguese british french dutch come loot us take yet do nation conquer anyone grab land culture history try enforce way life'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cleaning_text_lemm(data):\n",
    "    clean_data = []\n",
    "    for word in nltk.word_tokenize(data.lower()):\n",
    "        if (word not in stop_word and word not in punch):\n",
    "            clean_data.append(lemma.lemmatize(word, pos ='v'))\n",
    "    return \" \".join(clean_data)\n",
    "cleaning_text_lemm(paragraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What should we the pipeline till here \n",
    "Pipeline  = text ----> lower case ---> word tokenization ---> stopword ---> remove punctuations ---> stemming or lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
